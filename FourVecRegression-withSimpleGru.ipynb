{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.10 | packaged by conda-forge | (default, Feb 19 2021, 16:07:37) \n",
      "[GCC 9.3.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tqdm\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import json\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim \n",
    "import torch.utils.data as utils\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessor import load\n",
    "from supervised import *\n",
    "from four_vector_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/t3home000/spark/MassRegression/preprocessor.py:114: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  h5File = h5py.File(iFile)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 file \"GluGluHToTauTau_user_0.z\" (mode r+)>\n",
      "[[289.75   110.125  125.     ...   0.       0.       1.    ]\n",
      " [207.875   84.6875 125.     ...   0.       0.       1.    ]\n",
      " [221.875   91.5    125.     ...   0.       0.       1.    ]\n",
      " ...\n",
      " [286.25    62.875  125.     ...   0.       0.       1.    ]\n",
      " [258.5     73.125  125.     ...   0.       0.       1.    ]\n",
      " [310.75    95.25   125.     ...   0.       0.       1.    ]]\n",
      "(210492, 386)\n",
      "sv_chi20 found nan!!\n",
      "(210443, 300)\n",
      "(210443, 30, 10)\n",
      "(210443, 65)\n",
      "(210443, 5, 13)\n",
      "(210443, 12)\n"
     ]
    }
   ],
   "source": [
    "X_train_htt,X_test_htt,Xalt_train_htt,Xalt_test_htt,Xevt_train_htt,Xevt_test_htt,Y_train_htt,Y_test_htt,feat_train_htt,feat_test_htt = load('/data/t3home000/spark/GluGluHToTauTau_user_0.z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen4vec = np.apply_along_axis(fourvec, 1, Y_train_htt)\n",
    "jet4vec = np.apply_along_axis(fourvec, 1, Xevt_train_htt[:,-4:])\n",
    "\n",
    "Y_train_htt = gen4vec - jet4vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normlist_check = np.apply_along_axis(fourvec_norm, 1, Y_train_htt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17.35819907, 13.90187909, 41.51033232, ..., 61.8070506 ,\n",
       "       75.14978329, 31.16986747])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normlist_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(normlist_check,np.arange(0,200,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 file \"FlatTauTau_user_0.z\" (mode r+)>\n",
      "[[4.42500000e+02 9.88281250e+00 2.97500000e+01 ... 0.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [4.39500000e+02 7.62939453e-06 3.23750000e+01 ... 0.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [8.06000000e+02 4.87500000e+01 6.37500000e+01 ... 0.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " ...\n",
      " [1.24900000e+03 1.34250000e+02 1.72500000e+02 ... 0.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [3.72000000e+02 5.80000000e+01 7.47500000e+01 ... 0.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [2.77500000e+02 2.66875000e+01 5.36250000e+01 ... 0.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00]]\n",
      "(463459, 386)\n",
      "(463296, 300)\n",
      "(463296, 30, 10)\n",
      "(463296, 65)\n",
      "(463296, 5, 13)\n",
      "(463296, 12)\n"
     ]
    }
   ],
   "source": [
    "X_train_flat,X_test_flat,Xalt_train_flat,Xalt_test_flat,Xevt_train_flat,Xevt_test_flat,Y_train_flat,Y_test_flat,feat_train_flat,feat_test_flat = load('/data/t3home000/spark/FlatTauTau_user_0.z',maxevts=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_list = [0,0.2, 0.5, 0.8,.9]\n",
    "wp_choice = 4\n",
    "wp = wp_list[wp_choice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_split1, X_train_split2, Xalt_train_split1, Xalt_train_split2, Xevt_train_split1, Xevt_train_split2, y_train_split1, y_train_split2 = train_test_split(X_train_htt, Xalt_train_htt, Xevt_train_htt, Y_train_htt, test_size=wp, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixratio = round(X_train_split1.shape[0]/(X_train_flat.shape[0]+X_train_split1.shape[0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen4vec = np.apply_along_axis(fourvec, 1, Y_train_flat)\n",
    "jet4vec = np.apply_along_axis(fourvec, 1, Xevt_train_flat[:,-4:])\n",
    "\n",
    "Y_train_flat = gen4vec - jet4vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "normlist_check2 = np.apply_along_axis(fourvec_norm, 1, Y_train_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(normlist_check2,bins=np.arange(0,200,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vstack((X_train_split1, X_train_flat))\n",
    "\n",
    "Xalt_train = np.vstack((Xalt_train_split1, Xalt_train_flat))\n",
    "\n",
    "Xevt_train = np.vstack((Xevt_train_split1, Xevt_train_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387470, 30, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387470, 5, 13)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xalt_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387470, 12)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xevt_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_mean = np.mean(X_train, axis=0)\n",
    "part_std = np.std(X_train, axis=0)\n",
    "\n",
    "alt_mean = np.mean(Xalt_train, axis=0)\n",
    "alt_std = np.std(Xalt_train, axis=0)\n",
    "\n",
    "evt_mean = np.mean(Xevt_train, axis=0)\n",
    "evt_std = np.std(Xevt_train, axis=0)\n",
    "\n",
    "X_train = (X_train-part_mean)/part_std\n",
    "Xalt_train = (Xalt_train-alt_mean)/alt_std\n",
    "Xevt_train = (Xevt_train-evt_mean)/evt_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate((y_train_split1, Y_train_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "normlist = np.apply_along_axis(fourvec_norm, 1, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxnorm = np.max(normlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "587.5681455543696"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train/maxnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, Xalt_val, Xalt_test, Xevt_val, Xevt_test, y_val, y_test = train_test_split(X_test_htt, Xalt_test_htt, Xevt_test_htt, Y_test_htt, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = (y_val/maxnorm)\n",
    "y_test = (y_test/maxnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = (X_test-part_mean)/part_std\n",
    "Xalt_test = (Xalt_test-alt_mean)/alt_std\n",
    "Xevt_test = (Xevt_test-evt_mean)/evt_std\n",
    "\n",
    "X_val = (X_val-part_mean)/part_std\n",
    "Xalt_val = (Xalt_val-alt_mean)/alt_std\n",
    "Xevt_val = (Xevt_val-evt_mean)/evt_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'GeForce RTX 2080 Ti'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500\n",
    "N_EPOCHS = 80\n",
    "PRINT_INTERVAL = 2000\n",
    "NUM_WORKERS = 4\n",
    "LR = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleGru(\n",
      "  (gru1): GRU(10, 4, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (gru2): GRU(13, 4, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (linear1): Linear(in_features=20, out_features=40, bias=True)\n",
      "  (linear2): Linear(in_features=40, out_features=20, bias=True)\n",
      "  (linear3): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (linear4): Linear(in_features=10, out_features=8, bias=True)\n",
      "  (linear5): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm3): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm4): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleGru(\n",
       "  (gru1): GRU(10, 4, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (gru2): GRU(13, 4, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear1): Linear(in_features=20, out_features=40, bias=True)\n",
       "  (linear2): Linear(in_features=40, out_features=20, bias=True)\n",
       "  (linear3): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (linear4): Linear(in_features=10, out_features=8, bias=True)\n",
       "  (linear5): Linear(in_features=8, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (batchnorm1): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm3): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm4): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleGru()\n",
    "\n",
    "print(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = gruTrainData(torch.FloatTensor(X_train.astype(np.float)),torch.FloatTensor(Xalt_train.astype(np.float)),torch.FloatTensor(Xevt_train.astype(np.float)),torch.FloatTensor(y_train.astype(np.float)))\n",
    "val_data = gruTrainData(torch.FloatTensor(X_val.astype(np.float)),torch.FloatTensor(Xalt_val.astype(np.float)),torch.FloatTensor(Xevt_val.astype(np.float)),torch.FloatTensor(np.array(y_val).astype(np.float)))\n",
    "test_data = gruTestData(torch.FloatTensor(X_test.astype(np.float)),torch.FloatTensor(Xalt_test.astype(np.float)),torch.FloatTensor(Xevt_test.astype(np.float))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = utils.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = utils.DataLoader(dataset=val_data, batch_size=100)\n",
    "test_loader = utils.DataLoader(dataset=test_data, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourvec_loss(output, target):\n",
    "    diff = output-target\n",
    "    #print(\"diff:\",diff.shape)\n",
    "    norm = torch.dot(diff[:,0],diff[:,0])-torch.dot(diff[:,1],diff[:,1])-torch.dot(diff[:,2],diff[:,2])-torch.dot(diff[:,3],diff[:,3])\n",
    "    #print(\"norm:\",norm.shape)\n",
    "    loss = torch.sqrt(torch.sqrt(norm*norm))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # set the train mode\n",
    "    model.train()\n",
    "\n",
    "    # loss of the epoch\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    for x1,x2,x3, y in train_loader:\n",
    "        # reshape the data into [batch_size, 784]\n",
    "        x1,x2,x3,y = x1.to(device),x2.to(device),x3.to(device), y.to(device)\n",
    "\n",
    "        # update the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        y_pred = model(x1,x2,x3)\n",
    "\n",
    "        # reconstruction loss\n",
    "        #recon_loss = F.binary_cross_entropy(x_sample, x, size_average=False)\n",
    "\n",
    "        # kl divergence loss\n",
    "        #kl_loss = 0.5 * torch.sum(torch.exp(z_var) + z_mu**2 - 1.0 - z_var)\n",
    "\n",
    "        # total loss\n",
    "        #loss = recon_loss + kl_loss\n",
    "\n",
    "        #BCE loss\n",
    "        #print(y_pred.shape, y.shape)\n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    # set the evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # test loss for the data\n",
    "    test_loss = 0\n",
    "\n",
    "    # we don't need to track the gradients, since we are not updating the parameters during evaluation / testing\n",
    "    with torch.no_grad():\n",
    "        for x1,x2,x3, y in val_loader:\n",
    "            # reshape the data\n",
    "            #x = x.view(-1, 28 * 28)\n",
    "            x1,x2,x3,y = x1.to(device),x2.to(device),x3.to(device), y.to(device)\n",
    "            # forward pass\n",
    "            y_pred = model(x1,x2,x3)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "            # total loss\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "\n",
    "    return test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f\"/data/t3home000/spark/MassRegression/weights/fourVec_GRU_{mixratio}_v1.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 0.0008005, Test Loss: 0.0010057\n",
      "NOT SAVING\n",
      "Epoch 1, Train Loss: 0.0007971, Test Loss: 0.0010343\n",
      "NOT SAVING\n",
      "Epoch 2, Train Loss: 0.0007948, Test Loss: 0.0010184\n",
      "NOT SAVING\n",
      "Epoch 3, Train Loss: 0.0007903, Test Loss: 0.0010434\n",
      "NOT SAVING\n",
      "Epoch 4, Train Loss: 0.0007878, Test Loss: 0.0010497\n",
      "NOT SAVING\n",
      "Epoch 5, Train Loss: 0.0007835, Test Loss: 0.0010574\n",
      "NOT SAVING\n",
      "Epoch 6, Train Loss: 0.0007801, Test Loss: 0.0010785\n",
      "NOT SAVING\n",
      "Epoch 7, Train Loss: 0.0007770, Test Loss: 0.0010945\n",
      "NOT SAVING\n",
      "Epoch 8, Train Loss: 0.0007735, Test Loss: 0.0010902\n",
      "NOT SAVING\n",
      "Epoch 9, Train Loss: 0.0007710, Test Loss: 0.0011002\n",
      "NOT SAVING\n",
      "Epoch 10, Train Loss: 0.0007674, Test Loss: 0.0010728\n",
      "NOT SAVING\n",
      "Epoch 11, Train Loss: 0.0007642, Test Loss: 0.0011274\n",
      "NOT SAVING\n",
      "Epoch 12, Train Loss: 0.0007611, Test Loss: 0.0011165\n",
      "NOT SAVING\n",
      "Epoch 13, Train Loss: 0.0007579, Test Loss: 0.0011385\n",
      "NOT SAVING\n",
      "Epoch 14, Train Loss: 0.0007549, Test Loss: 0.0011431\n",
      "NOT SAVING\n",
      "Epoch 15, Train Loss: 0.0007524, Test Loss: 0.0011634\n",
      "NOT SAVING\n",
      "Epoch 16, Train Loss: 0.0007488, Test Loss: 0.0011411\n",
      "NOT SAVING\n",
      "Epoch 17, Train Loss: 0.0007457, Test Loss: 0.0011875\n",
      "NOT SAVING\n",
      "Epoch 18, Train Loss: 0.0007421, Test Loss: 0.0012046\n",
      "NOT SAVING\n",
      "Epoch 19, Train Loss: 0.0007388, Test Loss: 0.0011983\n",
      "NOT SAVING\n",
      "Epoch 20, Train Loss: 0.0007352, Test Loss: 0.0012195\n",
      "NOT SAVING\n",
      "Epoch 21, Train Loss: 0.0007333, Test Loss: 0.0012326\n",
      "NOT SAVING\n",
      "Epoch 22, Train Loss: 0.0007298, Test Loss: 0.0012463\n",
      "NOT SAVING\n",
      "Epoch 23, Train Loss: 0.0007276, Test Loss: 0.0012369\n",
      "NOT SAVING\n",
      "Epoch 24, Train Loss: 0.0007240, Test Loss: 0.0012364\n",
      "NOT SAVING\n",
      "Epoch 25, Train Loss: 0.0007212, Test Loss: 0.0012716\n",
      "NOT SAVING\n",
      "Epoch 26, Train Loss: 0.0007196, Test Loss: 0.0012509\n",
      "NOT SAVING\n",
      "Epoch 27, Train Loss: 0.0007168, Test Loss: 0.0012622\n",
      "NOT SAVING\n",
      "Epoch 28, Train Loss: 0.0007136, Test Loss: 0.0012599\n",
      "NOT SAVING\n",
      "Epoch 29, Train Loss: 0.0007104, Test Loss: 0.0012941\n",
      "NOT SAVING\n",
      "Epoch 30, Train Loss: 0.0007075, Test Loss: 0.0013064\n",
      "NOT SAVING\n",
      "Epoch 31, Train Loss: 0.0007053, Test Loss: 0.0013184\n",
      "NOT SAVING\n",
      "Epoch 32, Train Loss: 0.0007015, Test Loss: 0.0013300\n",
      "NOT SAVING\n",
      "Epoch 33, Train Loss: 0.0006999, Test Loss: 0.0013437\n",
      "NOT SAVING\n",
      "Epoch 34, Train Loss: 0.0006972, Test Loss: 0.0013492\n",
      "NOT SAVING\n",
      "Epoch 35, Train Loss: 0.0006946, Test Loss: 0.0013708\n",
      "NOT SAVING\n",
      "Epoch 36, Train Loss: 0.0006924, Test Loss: 0.0013666\n",
      "NOT SAVING\n",
      "Epoch 37, Train Loss: 0.0006893, Test Loss: 0.0013701\n",
      "NOT SAVING\n",
      "Epoch 38, Train Loss: 0.0006862, Test Loss: 0.0013923\n",
      "NOT SAVING\n",
      "Epoch 39, Train Loss: 0.0006847, Test Loss: 0.0014092\n",
      "NOT SAVING\n",
      "Epoch 40, Train Loss: 0.0006813, Test Loss: 0.0014192\n",
      "NOT SAVING\n",
      "Epoch 41, Train Loss: 0.0006794, Test Loss: 0.0014249\n",
      "NOT SAVING\n",
      "Epoch 42, Train Loss: 0.0006775, Test Loss: 0.0014133\n",
      "NOT SAVING\n",
      "Epoch 43, Train Loss: 0.0006746, Test Loss: 0.0014184\n",
      "NOT SAVING\n",
      "Epoch 44, Train Loss: 0.0006717, Test Loss: 0.0014251\n",
      "NOT SAVING\n",
      "Epoch 45, Train Loss: 0.0006704, Test Loss: 0.0014666\n",
      "NOT SAVING\n",
      "Epoch 46, Train Loss: 0.0006670, Test Loss: 0.0014607\n",
      "NOT SAVING\n",
      "Epoch 47, Train Loss: 0.0006651, Test Loss: 0.0014684\n",
      "NOT SAVING\n",
      "Epoch 48, Train Loss: 0.0006622, Test Loss: 0.0014853\n",
      "NOT SAVING\n",
      "Epoch 49, Train Loss: 0.0006611, Test Loss: 0.0014994\n",
      "NOT SAVING\n",
      "Epoch 50, Train Loss: 0.0006584, Test Loss: 0.0015175\n",
      "NOT SAVING\n",
      "Epoch 51, Train Loss: 0.0006559, Test Loss: 0.0015216\n",
      "NOT SAVING\n",
      "Epoch 52, Train Loss: 0.0006544, Test Loss: 0.0015102\n",
      "NOT SAVING\n",
      "Epoch 53, Train Loss: 0.0006524, Test Loss: 0.0015141\n",
      "NOT SAVING\n",
      "Epoch 54, Train Loss: 0.0006501, Test Loss: 0.0015199\n",
      "NOT SAVING\n",
      "Epoch 55, Train Loss: 0.0006486, Test Loss: 0.0015199\n",
      "NOT SAVING\n",
      "Epoch 56, Train Loss: 0.0006459, Test Loss: 0.0015653\n",
      "NOT SAVING\n",
      "Epoch 57, Train Loss: 0.0006431, Test Loss: 0.0015610\n",
      "NOT SAVING\n",
      "Epoch 58, Train Loss: 0.0006419, Test Loss: 0.0015687\n",
      "NOT SAVING\n",
      "Epoch 59, Train Loss: 0.0006402, Test Loss: 0.0015774\n",
      "NOT SAVING\n",
      "Epoch 60, Train Loss: 0.0006380, Test Loss: 0.0015729\n",
      "NOT SAVING\n",
      "Epoch 61, Train Loss: 0.0006355, Test Loss: 0.0015870\n",
      "NOT SAVING\n",
      "Epoch 62, Train Loss: 0.0006339, Test Loss: 0.0015999\n",
      "NOT SAVING\n",
      "Epoch 63, Train Loss: 0.0006320, Test Loss: 0.0015951\n",
      "NOT SAVING\n",
      "Epoch 64, Train Loss: 0.0006304, Test Loss: 0.0016093\n",
      "NOT SAVING\n",
      "Epoch 65, Train Loss: 0.0006288, Test Loss: 0.0016175\n",
      "NOT SAVING\n",
      "Epoch 66, Train Loss: 0.0006270, Test Loss: 0.0015877\n",
      "NOT SAVING\n",
      "Epoch 67, Train Loss: 0.0006260, Test Loss: 0.0016284\n",
      "NOT SAVING\n",
      "Epoch 68, Train Loss: 0.0006234, Test Loss: 0.0016335\n",
      "NOT SAVING\n",
      "Epoch 69, Train Loss: 0.0006213, Test Loss: 0.0016447\n",
      "NOT SAVING\n",
      "Epoch 70, Train Loss: 0.0006196, Test Loss: 0.0016533\n",
      "NOT SAVING\n",
      "Epoch 71, Train Loss: 0.0006182, Test Loss: 0.0016732\n",
      "NOT SAVING\n",
      "Epoch 72, Train Loss: 0.0006168, Test Loss: 0.0016609\n",
      "NOT SAVING\n",
      "Epoch 73, Train Loss: 0.0006154, Test Loss: 0.0016635\n",
      "NOT SAVING\n",
      "Epoch 74, Train Loss: 0.0006133, Test Loss: 0.0016767\n",
      "NOT SAVING\n",
      "Epoch 75, Train Loss: 0.0006125, Test Loss: 0.0016531\n",
      "NOT SAVING\n",
      "Epoch 76, Train Loss: 0.0006111, Test Loss: 0.0016562\n",
      "NOT SAVING\n",
      "Epoch 77, Train Loss: 0.0006091, Test Loss: 0.0016568\n",
      "NOT SAVING\n",
      "Epoch 78, Train Loss: 0.0006071, Test Loss: 0.0016696\n",
      "NOT SAVING\n",
      "Epoch 79, Train Loss: 0.0006061, Test Loss: 0.0016836\n",
      "NOT SAVING\n",
      "Epoch 80, Train Loss: 0.0006048, Test Loss: 0.0017040\n",
      "NOT SAVING\n",
      "Epoch 81, Train Loss: 0.0006036, Test Loss: 0.0017089\n",
      "NOT SAVING\n",
      "Epoch 82, Train Loss: 0.0006028, Test Loss: 0.0016962\n",
      "NOT SAVING\n",
      "Epoch 83, Train Loss: 0.0006008, Test Loss: 0.0017297\n",
      "NOT SAVING\n",
      "Epoch 84, Train Loss: 0.0005993, Test Loss: 0.0017269\n",
      "NOT SAVING\n",
      "Epoch 85, Train Loss: 0.0005972, Test Loss: 0.0017058\n",
      "NOT SAVING\n",
      "Epoch 86, Train Loss: 0.0005967, Test Loss: 0.0017365\n",
      "NOT SAVING\n",
      "Epoch 87, Train Loss: 0.0005947, Test Loss: 0.0017253\n",
      "NOT SAVING\n",
      "Epoch 88, Train Loss: 0.0005932, Test Loss: 0.0017370\n",
      "NOT SAVING\n",
      "Epoch 89, Train Loss: 0.0005923, Test Loss: 0.0017340\n",
      "NOT SAVING\n",
      "Epoch 90, Train Loss: 0.0005908, Test Loss: 0.0017428\n",
      "NOT SAVING\n",
      "Epoch 91, Train Loss: 0.0005898, Test Loss: 0.0017446\n",
      "NOT SAVING\n",
      "Epoch 92, Train Loss: 0.0005898, Test Loss: 0.0017648\n",
      "NOT SAVING\n",
      "Epoch 93, Train Loss: 0.0005878, Test Loss: 0.0017493\n",
      "NOT SAVING\n",
      "Epoch 94, Train Loss: 0.0005855, Test Loss: 0.0017701\n",
      "NOT SAVING\n",
      "Epoch 95, Train Loss: 0.0005846, Test Loss: 0.0017552\n",
      "NOT SAVING\n",
      "Epoch 96, Train Loss: 0.0005836, Test Loss: 0.0017390\n",
      "NOT SAVING\n",
      "Epoch 97, Train Loss: 0.0005834, Test Loss: 0.0017746\n",
      "NOT SAVING\n",
      "Epoch 98, Train Loss: 0.0005821, Test Loss: 0.0017828\n",
      "NOT SAVING\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-4b517aec35ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-f8b1bdd4b137>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mepoch_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m# reshape the data into [batch_size, 784]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/t3home000/spark/miniconda3/envs/fewshot/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/t3home000/spark/miniconda3/envs/fewshot/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/t3home000/spark/miniconda3/envs/fewshot/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/t3home000/spark/miniconda3/envs/fewshot/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/t3home000/spark/MassRegression/supervised.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_test_loss = 0.0009\n",
    "patience_counter = 0\n",
    "for e in range(500):\n",
    "\n",
    "    train_loss = train()\n",
    "    test_loss = test()\n",
    "\n",
    "    train_loss /= len(train_data)\n",
    "    test_loss /= len(val_data)\n",
    "\n",
    "    print(f'Epoch {e}, Train Loss: {train_loss:.7f}, Test Loss: {test_loss:.7f}')\n",
    "\n",
    "    if best_test_loss > test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        torch.save(model.state_dict(), f\"/data/t3home000/spark/MassRegression/weights/fourVec_GRU_{mixratio}_v1.h5\")\n",
    "        patience_counter = 1\n",
    "        print('saving model')\n",
    "    else:\n",
    "        print('NOT SAVING')\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter > 100:\n",
    "        print('patience limit reached')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_pred_list = np.array([],dtype=np.float)\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (x1,x2,x3) in enumerate(test_loader):\n",
    "        x1 = x1.to(device)\n",
    "        x2 = x2.to(device)\n",
    "        x3 = x3.to(device)\n",
    "        y_test_pred = model(x1,x2,x3)\n",
    "        y_test_pred = y_test_pred.cpu().numpy()\n",
    "        y_test_pred *= maxnorm\n",
    "        xevt = x3.cpu().numpy()\n",
    "        jet4vec = (xevt[:,-4:]*evt_std[-4:]) + evt_mean[-4:]\n",
    "        reconstructed = jet4vec + y_test_pred\n",
    "        #print(reconstructed.shape)\n",
    "        mass = np.apply_along_axis(fourvec_norm, 1, reconstructed)\n",
    "        \n",
    "        #y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        #y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list = np.append(y_pred_list,mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred_list,np.arange(0,1000,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,b,patches = plt.hist(predicted_mass,np.arange(60,300,3))\n",
    "plt.text(200, 1000, f'mean: {np.mean(predicted_mass):.2f}', fontsize=15)\n",
    "plt.text(200, 800, f'std: {np.std(predicted_mass):.2f}', fontsize=15)\n",
    "\n",
    "plt.text(200, 600, f'mixratio: {mixratio}%', fontsize=15)\n",
    "\n",
    "plt.text(65, 1200, f'm={b[bin_max][0]}', fontsize=13)\n",
    "\n",
    "plt.axvline(x=b[bin_max][0],color='r')\n",
    "plt.savefig('hadhad_mixratio_11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_max = np.where(n == n.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[bin_max][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relerr = (predicted_mass - 125) /125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(relerr,np.arange(-1.5,1.5,0.05));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 PowerAI Base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
